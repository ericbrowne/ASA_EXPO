---
title: "week10"
author: "Isabel and Eric"
date: "3/10/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages("naniar")
library(tidyverse)
library(naniar)
library(factoextra)
library(cluster)
library(caTools)
library(caret)
```

```{r}
#start putting together prettier script 
#read in 
#Social Vunerability Index

svi <- read.csv("SVI2018_US_COUNTY.csv")
#drop none numeric columns (county/state names)
svi_temp <- svi[-c(6:9)]
#drop margins of error 
#colnames(svi_temp)
svi_temp <- svi_temp[, grep('^EP', colnames(svi_temp)) ]
svi_temp$FIPS <- svi$FIPS
colnames(svi_temp)
svi_temp <- svi_temp %>% replace_with_na_all(condition = ~.x == -999) #converts -999 to na
print(dim(svi_temp))
svi_temp <- svi_temp %>% drop_na()  #drops NA - only lose one county 
print(dim(svi_temp))
```
## Merge Together SVI and ACS for Clustering.  Then, Standardize Dataset for Clustering
```{r}
svi_temp2 <- svi_temp[-c(2,3,4)]
view(svi_temp2)

acsMain<-read.csv('ACS_FINAL_v2.csv')
acsMain_svi_merged<-inner_join(svi_temp2,acsMain,by = 'FIPS',suffix = c('.svi','.acsMain'))
view(acsMain_svi_merged)


## Standardize Dataset:
acsMain_svi_merged_numeric<-subset(acsMain_svi_merged, select = -c(FIPS))
acsMain_svi_merged_numeric<-sapply(acsMain_svi_merged_numeric, as.numeric )
acsMain_svi_merged_numeric<-scale(acsMain_svi_merged_numeric)
view(acsMain_svi_merged_numeric)

## Need to Drop columns with All NA's


acsMain_svi_merged_numeric<-acsMain_svi_merged_numeric[ , colSums(is.na(acsMain_svi_merged_numeric)) < nrow(acsMain_svi_merged_numeric)]
view(acsMain_svi_merged_numeric)
dim(acsMain_svi_merged_numeric)
sum(is.na(acsMain_svi_merged_numeric))
## Need to Fill remaining NA's with 0's
acsMain_svi_merged_numeric[is.na(acsMain_svi_merged_numeric)]<-0
sum(is.na(acsMain_svi_merged_numeric))

FIPS<-acsMain_svi_merged$FIPS
length(FIPS)
acsMain_svi_scaled<-as.data.frame(acsMain_svi_merged_numeric)
acsMain_svi_scaled$FIPS <- FIPS
dim(acsMain_svi_scaled)

## 'acsMain_svi_scaled'  will be the dataset we use for clustering
## We will then add the Covid Deaths data from the NYT to use for Linear Regression
```

## Clustering Process.
```{r}
#get ideal number of clusters 
fviz_nbclust(acsMain_svi_scaled, FUN = hcut, method = "wss")
fviz_nbclust(acsMain_svi_scaled, FUN = hcut, method = "silhouette")
```


```{r}
#ward hierarchical clustering 
d <- dist(acsMain_svi_scaled, method = "euclidean") #translate data to distance
fit <- hclust(d, method = "ward.D2")
plot(fit, cex = 0.6, hang = -1)
groups_w <- cutree(fit, k = 3)
table(groups_w)
length(groups_w)
#plot.new()
#rect.hclust(fit, k=5, border="red")
```




```{r}
fviz_cluster(list(data = acsMain_svi_scaled, cluster = groups_w))
```


```{r}
fviz_nbclust(acsMain_svi_scaled, FUN = hcut, method = "wss")
#complete hierarchical clustering 
d <- dist(acsMain_svi_scaled, method = "euclidean") #translate data to distance
fit <- hclust(d, method = "complete")
plot(fit)
groups_c <- cutree(fit, k = 4)
table(groups_c)
length(groups_c)
#plot.new()
#rect.hclust(fit, k=5, border="red")
fviz_cluster(list(data = acsMain_svi_scaled, cluster = groups_c))
```

```{r}
## agglomerative nesting 
#We are calling this 'agnes' clustering for ease of use
library(cluster)
hc_a <- agnes(acsMain_svi_scaled, method = "average") # dendrogram
plot(hc_a)
groups_a <- cutree(as.hclust(hc_a), k = 3)
table(groups_a)
length(groups_a)
hc_a$ac
fviz_cluster(list(data = acsMain_svi_scaled, cluster = groups_a))
```



```{r}
#diana clustering
# Cut diana() tree into 
hc_d <- diana(acsMain_svi_scaled) # dendrogram
plot(hc_d)
groups_d <- cutree(as.hclust(hc_d), k = 6)
table(groups_d)
hc_d$dc
fviz_cluster(list(data = acsMain_svi_scaled, cluster = groups_d))
```

## NEED TO DO WHEN LANDING IN DENVER!!
```{r}
#add clusters to new dataframe: acsMain_svi_scaled

acsMain_svi_scaled$cluster_ward = groups_w
acsMain_svi_scaled$cluster_complete = groups_c
acsMain_svi_scaled$cluster_agnes = groups_a
acsMain_svi_scaled$cluster_diana = groups_d
table(groups_w)
table(groups_c)
table(groups_a)
table(groups_d)
#add in population and 
pop <- as_tibble(cbind(svi$FIPS, svi$E_TOTPOP))
#get updated covid data
library (readr)
cv<-read.csv(url("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"))
#drop date bc we want aggregation
cv <- cv[-c(1)]
total_cases <- aggregate(cv$cases, by=list(fips=cv$fips), FUN=sum)
total_death <- aggregate(cv$deaths, by=list(fips=cv$fips), FUN = sum)
cv2 <- cbind(total_cases, total_death)
names(cv2) <- c("fips", "total_cases", "fips", "total_death")
write_csv(cv2, 'covid_data.csv')


## READ in Covid Deaths by County
cv2 <- read_csv("covid_data.csv")
cv2 <- cv2[c(1, 2, 4)]
#fix later
names(cv2) <- c("FIPS", "total_cases", "total_death")
#add covid data to SVI

## MERGE Together Deaths and ACS/SVI scaled:
dim(acsMain_svi_scaled)
acsMain_svi_scaled <- merge(cv2, acsMain_svi_scaled, by='FIPS') 
dim(acsMain_svi_scaled) # check dimensions to make sure we added cols:

## Merge in Population:
names(pop) <- c("FIPS", "population")
acsMain_svi_scaled <- merge(pop, acsMain_svi_scaled, by='FIPS') 
#adjust covid totals to ratios of population
acsMain_svi_scaled $case_by_pop <- acsMain_svi_scaled $total_cases / acsMain_svi_scaled $population
acsMain_svi_scaled $death_by_pop <- acsMain_svi_scaled $total_death / acsMain_svi_scaled $population

## CONSTRUCT our Response variable: Covid Impact
# We will be using this variable as our response variable to predict using Linear Regression
acsMain_svi_scaled $covid_impact = acsMain_svi_scaled $case_by_pop + acsMain_svi_scaled $death_by_pop
dim(acsMain_svi_scaled)
```

## Linear Regression: Full Datasets, Training/Testing Sets

```{r}
## Now make subsets depending on cluster method.  Then make the 'ID' variable a category:
# subset(mydata, select = -c(x,z) )
acsMain_svi_scaled_WARD<-subset(acsMain_svi_scaled, select = -c(cluster_complete,cluster_diana,cluster_agnes,case_by_pop,death_by_pop,total_death,total_cases))
acsMain_svi_scaled_COMPLETE<-subset(acsMain_svi_scaled, select = -c(cluster_ward,cluster_diana,cluster_agnes,case_by_pop,death_by_pop,total_death,total_cases))
acsMain_svi_scaled_AGNES<-subset(acsMain_svi_scaled, select = -c(cluster_ward,cluster_complete,cluster_diana,case_by_pop,death_by_pop,total_death,total_cases))
acsMain_svi_scaled_DIANA<-subset(acsMain_svi_scaled, select = -c(cluster_ward,cluster_complete,cluster_agnes,case_by_pop,death_by_pop,total_death,total_cases))

## Now change the clusterID variable in each subset to be a factor to be used in linear regression:
#as.factor(mtcars$am): Example
acsMain_svi_scaled_WARD$cluster_ward<-as.factor(acsMain_svi_scaled_WARD$cluster_ward)
acsMain_svi_scaled_COMPLETE$cluster_complete<-as.factor(acsMain_svi_scaled_COMPLETE$cluster_complete)
acsMain_svi_scaled_AGNES$cluster_agnes<-as.factor(acsMain_svi_scaled_AGNES$cluster_agnes)
acsMain_svi_scaled_DIANA$cluster_diana<-as.factor(acsMain_svi_scaled_DIANA$cluster_diana)

## Now we are ready for GLM of predicting Covid Impact (death_by_pop + case_by_pop)
## The GLM with the highest R2 and lowest RMSE will correspond to the preferred clustering method
## But before we do that, lets first plot to see if the response variable is approximately normally distributed:
plot(density(acsMain_svi_scaled$covid_impact),main='Density Plot: Covid Impact per County (Response Variable)',ylab='Frequency')

## It appears to be approximately normally distributed, so lets continue with multiple linear regression:
## First, lets split into Training and Testing Sets
## We will not be using a Validation Set, as out data sample is too small at only ~ 800 rows

# Randomly identifies therows equal to sample size ( defined in previous instruction) from  all the rows of Smarket dataset and stores the row number in train_ind
set.seed(42)
train_size<-floor(0.7*nrow(acsMain_svi_scaled))
train_ind<- sample(seq_len(nrow(acsMain_svi_scaled)),size = train_size)  


## WARD
train_ward<-acsMain_svi_scaled_WARD[train_ind,] #creates the training dataset with row numbers stored in train_ind
test_ward<-acsMain_svi_scaled_WARD[-train_ind,]

## COMPLETE

train_complete<-acsMain_svi_scaled_COMPLETE[train_ind,] #creates the training dataset with row numbers stored in train_ind
test_complete<-acsMain_svi_scaled_COMPLETE[-train_ind,]

## AGNES

train_agnes<-acsMain_svi_scaled_AGNES[train_ind,] #creates the training dataset with row numbers stored in train_ind
test_agnes<-acsMain_svi_scaled_AGNES[-train_ind,]

## DIANA

train_diana<-acsMain_svi_scaled_DIANA[train_ind,] #creates the training dataset with row numbers stored in train_ind
test_diana<-acsMain_svi_scaled_DIANA[-train_ind,]

## Run Models on entire subset-Dataset:
reg_full_ward<-lm(covid_impact~.,data=acsMain_svi_scaled_WARD)
summary(reg_full_ward)

reg_full_complete<-lm(covid_impact~.,data=acsMain_svi_scaled_COMPLETE)
summary(reg_full_complete)

reg_full_agnes<-lm(covid_impact~.,data=acsMain_svi_scaled_AGNES)
summary(reg_full_agnes)

reg_full_diana<-lm(covid_impact~.,data=acsMain_svi_scaled_DIANA)
summary(reg_full_diana)



## Now that we have our training and testing sets for each subset of clustering method, lets run Linear Regression
reg_ward<-lm(covid_impact ~.,data=train_ward)
reg_complete<-lm(covid_impact ~ .,data=train_complete)
reg_agnes<-lm(covid_impact ~ .,data=train_agnes)
reg_diana<-lm(covid_impact ~ .,data=train_diana)


## Calculate Training Error:
ward_train_preds<-predict(reg_ward,train_ward)
print(RMSE(ward_train_preds,train_ward$covid_impact))

complete_train_preds<-predict(reg_complete,train_complete)
print(RMSE(complete_train_preds,train_complete$covid_impact))

agnes_train_preds<-predict(reg_agnes,train_agnes)
print(RMSE(agnes_train_preds,train_agnes$covid_impact))

diana_train_preds<-predict(reg_diana,train_diana)
print(RMSE(diana_train_preds,train_diana$covid_impact))


## Calculate Testing Error and R-squared:
ward_test_preds<-predict(reg_ward,test_ward)
print(RMSE(ward_test_preds,test_ward$covid_impact))


complete_test_preds<-predict(reg_complete,test_complete)
print(RMSE(complete_test_preds,test_complete$covid_impact))

agnes_test_preds<-predict(reg_agnes,test_agnes)
print(RMSE(agnes_test_preds,test_agnes$covid_impact))

diana_test_preds<-predict(reg_diana,test_diana)
print(RMSE(diana_test_preds,test_diana$covid_impact))



## Display Testing Model Summaries:
# check R-squared values here:  getting ~0.5 which is half decent
summary(reg_ward) 
summary(reg_complete)
summary(reg_agnes)
summary(reg_diana)

```









```{r}
ward <- aggregate(svi_temp, list(acsMain$cluster_ward), mean)
ward
```

```{r}
completeclust <- aggregate(svi_temp, list(svi_temp$cluster_complete), mean)
completeclust
```


```{r}
agnes <- aggregate(svi_temp, list(svi_temp$cluster_agnes), mean)
agnes
```


```{r}
diana <- aggregate(svi_temp, list(svi_temp$cluster_diana), mean)
diana
```

## Cluster Evaluation
```{r}
#remove similar features 
eval_dat <- select(svi_temp, -c(FIPS, total_cases, total_death))
#combine covid death and cases 
eval_dat$covid <- eval_dat$case_by_pop + eval_dat$death_by_pop
eval_dat <- select(eval_dat, -c(case_by_pop, death_by_pop))
#base level prediction 
noclust <- select(eval_dat, -c(cluster_diana, cluster_agnes, cluster_complete, cluster_ward))
base_model <- glm(covid ~ ., data=noclust)
summary(base_model)
print(with(summary(base_model), 1 - deviance/null.deviance))
```

```{r}
#ward evaluate 
ward_dat <- select(eval_dat, -c(cluster_diana, cluster_agnes, cluster_complete))
#ward_1 <- subset(ward_dat, cluster_ward==1)
ward_model <- glm(covid ~ ., data=ward_dat)
summary(ward_model)
print(with(summary(ward_model), 1 - deviance/null.deviance))
```
```{r}
#complete evaluate 
complete_dat <- select(eval_dat, -c(cluster_diana, cluster_agnes, cluster_ward))
#ward_1 <- subset(ward_dat, cluster_ward==1)
complete_model <- glm(covid ~ ., data=complete_dat)
summary(complete_model)
print(with(summary(complete_model), 1 - deviance/null.deviance))
```

```{r}
#agnes evaluate 
agnes_dat <- select(eval_dat, -c(cluster_diana, cluster_complete, cluster_ward))
#ward_1 <- subset(ward_dat, cluster_ward==1)
agnes_model <- glm(covid ~ ., data=agnes_dat)
summary(agnes_model)
print(with(summary(agnes_model), 1 - deviance/null.deviance))
```

```{r}
#diana evaluate 
diana_dat <- select(eval_dat, -c(cluster_agnes, cluster_complete, cluster_ward))
#ward_1 <- subset(ward_dat, cluster_ward==1)
diana_model <- glm(covid ~ ., data=diana_dat)
summary(diana_model)
print(with(summary(diana_model), 1 - deviance/null.deviance))
```