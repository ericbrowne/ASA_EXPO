---
title: "week10"
author: "Isabel and Eric"
date: "3/10/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages("naniar")
library(tidyverse)
library(naniar)
library(factoextra)
library(cluster)
library(caTools)
library(caret)
```

```{r}
#start putting together prettier script 
#read in 
#Social Vunerability Index

svi <- read.csv("SVI2018_US_COUNTY.csv")
#drop none numeric columns (county/state names)
svi_temp <- svi[-c(6:9)]
#drop margins of error 
#colnames(svi_temp)
svi_temp <- svi_temp[, grep('^EP', colnames(svi_temp)) ]
svi_temp$FIPS <- svi$FIPS
colnames(svi_temp)
svi_temp <- svi_temp %>% replace_with_na_all(condition = ~.x == -999) #converts -999 to na
print(dim(svi_temp))
svi_temp <- svi_temp %>% drop_na()  #drops NA - only lose one county 
print(dim(svi_temp))
```
## Merge Together SVI and ACS for Clustering.  Then, Standardize Dataset for Clustering
```{r}
svi_temp2 <- svi_temp[-c(2,3,4)]
view(svi_temp2)

acsMain<-read.csv('ACS_FINAL_v2.csv')
acsMain_svi_merged<-inner_join(svi_temp2,acsMain,by = 'FIPS',suffix = c('.svi','.acsMain'))
view(acsMain_svi_merged)


## Standardize Dataset:
acsMain_svi_merged_numeric<-subset(acsMain_svi_merged, select = -c(FIPS))
acsMain_svi_merged_numeric<-sapply(acsMain_svi_merged_numeric, as.numeric )
acsMain_svi_merged_numeric<-scale(acsMain_svi_merged_numeric)
view(acsMain_svi_merged_numeric)

## Need to Drop columns with All NA's


acsMain_svi_merged_numeric<-acsMain_svi_merged_numeric[ , colSums(is.na(acsMain_svi_merged_numeric)) < nrow(acsMain_svi_merged_numeric)]
view(acsMain_svi_merged_numeric)
dim(acsMain_svi_merged_numeric)
sum(is.na(acsMain_svi_merged_numeric))
## Need to Fill remaining NA's with 0's
acsMain_svi_merged_numeric[is.na(acsMain_svi_merged_numeric)]<-0
sum(is.na(acsMain_svi_merged_numeric))

FIPS<-acsMain_svi_merged$FIPS
length(FIPS)
acsMain_svi_scaled<-as.data.frame(acsMain_svi_merged_numeric)
acsMain_svi_scaled$FIPS <- FIPS
dim(acsMain_svi_scaled)

## 'acsMain_svi_scaled'  will be the dataset we use for clustering
## We will then add the Covid Deaths data from the NYT to use for Linear Regression

# Write to CSV:
write.csv(acsMain_svi_scaled,'ACS_SVI_SCALED.csv')
```

## Clustering Process.
```{r}
#get ideal number of clusters 
fviz_nbclust(acsMain_svi_scaled, FUN = hcut, method = "wss")
fviz_nbclust(acsMain_svi_scaled, FUN = hcut, method = "silhouette")
```


```{r}
#ward hierarchical clustering 
d <- dist(acsMain_svi_merged, method = "euclidean") #translate data to distance
fit <- hclust(d, method = "ward.D2")
plot(fit, cex = 0.6, hang = -1)
groups_w <- cutree(fit, k = 3)
table(groups_w)
#plot.new()
#rect.hclust(fit, k=5, border="red")
```




```{r}
fviz_cluster(list(data = acsMain_svi_scaled, cluster = groups_w))
```


```{r}
fviz_nbclust(svi_temp, FUN = hcut, method = "wss")
#complete hierarchical clustering 
#just thrwoing shit at the wall and seeing what sticks
d <- dist(svi_temp, method = "euclidean") #translate data to distance
fit <- hclust(d, method = "complete")
plot(fit)
groups_c <- cutree(fit, k = 3)
table(groups_c)
#plot.new()
#rect.hclust(fit, k=5, border="red")
fviz_cluster(list(data = svi_temp, cluster = groups_c))
```

```{r}
#agglomerative nesting 
#agnes clustering 
library(cluster)
hc_a <- agnes(svi_temp, method = "average")
groups_a <- cutree(as.hclust(hc_a), k = 3)
table(groups_a)
hc_a$ac
fviz_cluster(list(data = svi_temp, cluster = groups_a))
```



```{r}
#diana clustering
# Cut diana() tree into 
hc_d <- diana(svi_temp)
groups_d <- cutree(as.hclust(hc_d), k = 3)
table(groups_d)
hc_d$dc
fviz_cluster(list(data = svi_temp, cluster = groups_d))
```


```{r}
#add clusters to new dataframe: acsMain_svi_scaled

svi_temp$cluster_ward = groups_w
svi_temp$cluster_complete = groups_c
svi_temp$cluster_agnes = groups_a
svi_temp$cluster_diana = groups_d
table(groups_w)
table(groups_c)
table(groups_a)
table(groups_d)
#add in population and 
pop <- as_tibble(cbind(svi$FIPS, svi$E_TOTPOP))
#get updated covid data
library (readr)
cv<-read.csv(url("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"))
#drop date bc we want aggregation
cv <- cv[-c(1)]
total_cases <- aggregate(cv$cases, by=list(fips=cv$fips), FUN=sum)
total_death <- aggregate(cv$deaths, by=list(fips=cv$fips), FUN = sum)
cv2 <- cbind(total_cases, total_death)
names(cv2) <- c("fips", "total_cases", "fips", "total_death")
write_csv(cv2, 'covid_data.csv')
cv2 <- read_csv("covid_data.csv")
cv2 <- cv2[c(1, 2, 4)]
#fix later
names(cv2) <- c("FIPS", "total_cases", "total_death")
#add covid data to SVI
svi_temp <- merge(cv2, svi_temp, by='FIPS') 
#add population
names(pop) <- c("FIPS", "population")
svi_temp <- merge(pop, svi_temp, by='FIPS') 
#adjust covid totals to ratios of population
svi_temp$case_by_pop <- svi_temp$total_cases / svi_temp$population
svi_temp$death_by_pop <- svi_temp$total_death / svi_temp$population
svi_temp$covid_impact = svi_temp$case_by_pop + svi_temp$death_by_pop
```

## Eric Continuing Work: Linear Regression

```{r}
## Drop some columns
#df <- mydata[ -c(1,3:4) ]
svi_temp2 <- svi_temp[-c(2,3,4)]
view(svi_temp2)

## Now we need to merge together the ACS Main estimates, and SVI_temp2:
acsMain<-read.csv('final_ACS_estimates.csv')  # THIS NEEDS TO BE RE-DONE.  THE ACS ESTIMATES ARE NOT FORMATTED CORRECTLY BY ERIC
view(acsMain)

#merge together on FIPS code (inner join)
# inner_join(x, y, by = NULL, copy = FALSE, suffix = c(".x", ".y")
# left_join(x, y, by = NULL, copy = FALSE, suffix = c(".x", ".y"), ...)
acsMain_svi_merged<-inner_join(svi_temp2,acsMain,by = 'FIPS',suffix = c('.svi','.acsMain'))
view(acsMain_svi_merged)

## Now make subsets depending on cluster method.  Then make the 'ID' variable a category:
# subset(mydata, select = -c(x,z) )
acsMain_svi_merged_WARD<-subset(acsMain_svi_merged, select = -c(cluster_complete,cluster_diana,cluster_agnes,case_by_pop,death_by_pop,X))
acsMain_svi_merged_COMPLETE<-subset(acsMain_svi_merged, select = -c(cluster_ward,cluster_diana,cluster_agnes,case_by_pop,death_by_pop))
acsMain_svi_merged_AGNES<-subset(acsMain_svi_merged, select = -c(cluster_ward,cluster_complete,cluster_diana,case_by_pop,death_by_pop))
acsMain_svi_merged_DIANA<-subset(acsMain_svi_merged, select = -c(cluster_ward,cluster_complete,cluster_agnes,case_by_pop,death_by_pop))

## Now change the clusterID variable in each subset to be a factor to be used in linear regression:
#as.factor(mtcars$am): Example
acsMain_svi_merged_WARD$cluster_ward<-as.factor(acsMain_svi_merged_WARD$cluster_ward)
acsMain_svi_merged_COMPLETE$cluster_complete<-as.factor(acsMain_svi_merged_COMPLETE$cluster_complete)
acsMain_svi_merged_AGNES$cluster_agnes<-as.factor(acsMain_svi_merged_AGNES$cluster_agnes)
acsMain_svi_merged_DIANA$cluster_diana<-as.factor(acsMain_svi_merged_DIANA$cluster_diana)

## Now we are ready for GLM of predicting Covid Impact (death_by_pop + case_by_pop)
## The GLM with the highest R2 and lowest RMSE will correspond to the preferred clustering method
## But before we do that, lets first plot to see if the response variable is approximately normally distributed:
plot(density(acsMain_svi_merged$covid_impact),main='Density Plot: Covid Impact per County (Response Variable)',ylab='Frequency')

## It appears to be approximately normally distributed, so lets continue with multiple linear regression:
## First, lets split into Training and Testing Sets
## We will not be using a Validation Set, as out data sample is too small at only ~ 800 rows

set.seed(42)
train_size<-floor(0.7*nrow(acsMain_svi_merged))
train_ind<- sample(seq_len(nrow(acsMain_svi_merged)),size = train_size)  # Randomly identifies therows equal to sample size ( defined in previous instruction) from  all the rows of Smarket dataset and stores the row number in train_ind

## WARD
train_ward<-acsMain_svi_merged_WARD[train_ind,] #creates the training dataset with row numbers stored in train_ind
test_ward<-acsMain_svi_merged_WARD[-train_ind,]

## COMPLETE

train_complete<-acsMain_svi_merged_COMPLETE[train_ind,] #creates the training dataset with row numbers stored in train_ind
test_complete<-acsMain_svi_merged_COMPLETE[-train_ind,]

## AGNES

train_agnes<-acsMain_svi_merged_AGNES[train_ind,] #creates the training dataset with row numbers stored in train_ind
test_agnes<-acsMain_svi_merged_AGNES[-train_ind,]

## DIANA

train_diana<-acsMain_svi_merged_DIANA[train_ind,] #creates the training dataset with row numbers stored in train_ind
test_diana<-acsMain_svi_merged_DIANA[-train_ind,]


## Now that we have our training and testing sets for each subset of clustering method, lets run Linear Regression
reg_ward<-lm(covid_impact ~.,data=train_ward)
reg_complete<-lm(covid_impact ~ .,data=train_complete)
reg_agnes<-lm(covid_impact ~ .,data=train_agnes)
reg_diana<-lm(covid_impact ~ .,data=train_diana)


## Calculate Training Error:
ward_train_preds<-predict(reg_ward,train_ward)
print(RMSE(ward_train_preds,train_ward$covid_impact))

complete_train_preds<-predict(reg_complete,train_complete)
print(RMSE(complete_train_preds,train_complete$covid_impact))

agnes_train_preds<-predict(reg_agnes,train_agnes)
print(RMSE(agnes_train_preds,train_agnes$covid_impact))

diana_train_preds<-predict(reg_diana,train_diana)
print(RMSE(diana_train_preds,train_diana$covid_impact))


## Calculate Testing Error and R-squared:
ward_test_preds<-predict(reg_ward,test_ward)
print(RMSE(ward_test_preds,test_ward$covid_impact))


complete_test_preds<-predict(reg_complete,test_complete)
print(RMSE(complete_test_preds,test_complete$covid_impact))

agnes_test_preds<-predict(reg_agnes,test_agnes)
print(RMSE(agnes_test_preds,test_agnes$covid_impact))

diana_test_preds<-predict(reg_diana,test_diana)
print(RMSE(diana_test_preds,test_diana$covid_impact))



## Display Testing Model Summaries:
# check R-squared values here:  getting ~0.5 which is half decent
summary(reg_ward) 
summary(reg_complete)
summary(reg_agnes)
summary(reg_diana)

```









```{r}
ward <- aggregate(svi_clust, list(svi_clust$cluster_ward), mean)
ward
```

```{r}
completeclust <- aggregate(svi_clust, list(svi_clust$cluster_complete), mean)
completeclust
```


```{r}
agnes <- aggregate(svi_clust, list(svi_clust$cluster_agnes), mean)
agnes
```


```{r}
diana <- aggregate(svi_clust, list(svi_clust$cluster_diana), mean)
diana
```

# Cluster Evaluation
```{r}
#base level prediction 
noclust <- select(svi_temp, -c(cluster_diana, cluster_agnes, cluster_complete, cluster_ward))
base_model <- glm(case_by_pop ~ ., data=svi_temp)
summary(base_model)
print(with(summary(base_model), 1 - deviance/null.deviance))
```

```{r}
#ward evaluate 
ward_dat <- select(svi_temp, -c(cluster_diana, cluster_agnes, cluster_complete))
#ward_1 <- subset(ward_dat, cluster_ward==1)
ward_model <- glm(case_by_pop ~ ., data=ward_dat)
summary(ward_model)
print(with(summary(ward_model), 1 - deviance/null.deviance))
```
```{r}
#complete evaluate 
complete_dat <- select(svi_temp, -c(cluster_diana, cluster_agnes, cluster_ward))
#ward_1 <- subset(ward_dat, cluster_ward==1)
complete_model <- glm(case_by_pop ~ ., data=complete_dat)
summary(complete_model)
print(with(summary(complete_model), 1 - deviance/null.deviance))
```

```{r}
#agnes evaluate 
agnes_dat <- select(svi_temp, -c(cluster_diana, cluster_complete, cluster_ward))
#ward_1 <- subset(ward_dat, cluster_ward==1)
agnes_model <- glm(case_by_pop ~ ., data=agnes_dat)
summary(agnes_model)
print(with(summary(agnes_model), 1 - deviance/null.deviance))
```

```{r}
#diana evaluate 
diana_dat <- select(svi_temp, -c(cluster_agnes, cluster_complete, cluster_ward))
#ward_1 <- subset(ward_dat, cluster_ward==1)
diana_model <- glm(case_by_pop ~ ., data=diana_dat)
summary(diana_model)
print(with(summary(diana_model), 1 - deviance/null.deviance))